{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "* 求解机器学习的步骤分为学习和推理两个阶段\n",
    "* 学习阶段是通过训练数据来调整模型的参数，使模型能够更好地拟合数据\n",
    "* 推理阶段是使用训练好的模型对新数据进行预测"
   ],
   "id": "6de1d6b507e2f9c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# coding: utf-8\n",
    "# 该方法下载 MNIST 数据集，并将其转换为 pickle 文件\n",
    "# pkl 文件是 Python 的一种序列化文件格式，可以将 Python 对象保存到文件中，方便后续使用\n",
    "try:\n",
    "    import urllib.request # 倒入 urllib.request 用于下载文件\n",
    "except ImportError:\n",
    "    raise ImportError('You should use Python 3.x')\n",
    "import os.path # 用于处理文件和目录路径\n",
    "import gzip # 用于解压缩 gzip 文件\n",
    "import pickle # 用于序列化和反序列化 Python 对象\n",
    "import os # 用于处理文件和目录路径\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "url_base = 'https://ossci-datasets.s3.amazonaws.com/mnist/'  # MNIST 数据集的下载地址\n",
    "key_file = {\n",
    "    'train_img':'train-images-idx3-ubyte.gz', # 训练图像文件名\n",
    "    'train_label':'train-labels-idx1-ubyte.gz', # 训练标签文件名\n",
    "    'test_img':'t10k-images-idx3-ubyte.gz', # 测试图像文件名\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz' # 测试标签文件名\n",
    "}\n",
    "\n",
    "dataset_dir = \"/Users/Crimson/PycharmProjects/DeepLearning/pickle\"  # 获取当前文件的目录\n",
    "save_file = dataset_dir + \"/mnist.pkl\" # 保存 pickle 文件的路径\n",
    "\n",
    "train_num = 60000 # 训练数据的数量\n",
    "test_num = 10000 # 测试数据的数量\n",
    "img_dim = (1, 28, 28) # 图像的维度，1表示灰度图，28x28 表示图像的大小\n",
    "img_size = 784 # 图像的大小，28x28=784\n",
    "\n",
    "# 下载文件\n",
    "def _download(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        return\n",
    "\n",
    "    print(\"Downloading \" + file_name + \" ... \")\n",
    "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
    "    print(\"Done\")\n",
    "\n",
    "# 下载  MNIST 数据集\n",
    "def download_mnist():\n",
    "    for v in key_file.values():\n",
    "       _download(v)\n",
    "\n",
    "# 读取标签文件，并转换为 NumPy数组\n",
    "def _load_label(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "\n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f: # 以二进制读取 gzip 文件， rb 表示读取二进制文件\n",
    "            labels = np.frombuffer(f.read(), np.uint8, offset=8) # 从文件中读取数据，并转换为 NumPy 数组， offset=8 表示跳过前 8 个字节，因为前 8 个字节是文件头信息。np.frombuffer 用于将字节数据转换为 NumPy 数组\n",
    "    print(\"Done\")\n",
    "\n",
    "    return labels\n",
    "\n",
    "# 读取图像文件，并转换为 NumPy数组\n",
    "def _load_img(file_name):\n",
    "    file_path = dataset_dir + \"/\" + file_name\n",
    "\n",
    "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16) # offset=16 表示跳过前 16 个字节，因为前 16 个字节是文件头信息\n",
    "    data = data.reshape(-1, img_size) # 将数据转换为二维数组，reshape(-1, img_size) 表示将数据转换为行数不确定，列数为 img_size 的二维数组\n",
    "    print(\"Done\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# 将数据转换为 pickle 文件\n",
    "def _convert_numpy():\n",
    "    dataset = {}\n",
    "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
    "    dataset['train_label'] = _load_label(key_file['train_label'])\n",
    "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
    "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
    "\n",
    "    return dataset\n",
    "\n",
    "# 初始化 MNIST 数据集\n",
    "def init_mnist():\n",
    "    download_mnist()\n",
    "    dataset = _convert_numpy()\n",
    "    print(\"Creating pickle file ...\")\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(dataset, f, -1)\n",
    "    print(\"Done!\")\n",
    "\n",
    "# 将标签转换为 one-hot 数组, one-hot 数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组, 里面的元素只有一个元素为 1，其他元素为 0，因为 MNIST 数据集有 10 个类别，所以 one-hot 数组的长度为 10。为1的元素表示该样本的类别\n",
    "def _change_one_hot_label(X):\n",
    "    T = np.zeros((X.size, 10))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "\n",
    "    return T\n",
    "\n",
    "# 读入 MNIST 数据集\n",
    "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
    "    \"\"\"读入MNIST数据集\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    normalize : 将图像的像素值正规化为0.0~1.0\n",
    "    one_hot_label :\n",
    "        one_hot_label为True的情况下，标签作为one-hot数组返回\n",
    "        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组\n",
    "    flatten : 是否将图像展开为一维数组\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (训练图像, 训练标签), (测试图像, 测试标签)\n",
    "    \"\"\"\n",
    "    if not os.path.exists(save_file):\n",
    "        init_mnist()\n",
    "\n",
    "    with open(save_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "\n",
    "    if normalize:\n",
    "        for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].astype(np.float32)\n",
    "            dataset[key] /= 255.0\n",
    "\n",
    "    if one_hot_label:\n",
    "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
    "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
    "\n",
    "    if not flatten:\n",
    "         for key in ('train_img', 'test_img'):\n",
    "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
    "\n",
    "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    init_mnist()\n"
   ],
   "id": "16608bd3126ad151",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 为了导入父目录的文件而进行的设定\n",
    "((x_train, t_train), (x_test, t_test)) = load_mnist(flatten=True, normalize=False) # 读入 MNIST 数据集\n",
    "print(x_train.shape) # (60000, 784)\n",
    "print(t_train.shape) # (60000,)\n",
    "print(x_test.shape)  # (10000, 784)\n",
    "print(t_test.shape)  # (10000,)"
   ],
   "id": "2a6b455b46aeda32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "经过前面两个方法的处理，x_train 和 x_test 分别是训练数据和测试数据，t_train 和 t_test 分别是训练标签和测试标签。\n",
    "* x_train 的形状是 (60000, 784)，表示有 60000 张图片，每张图片有 784 个像素点\n",
    "* t_train 的形状是 (60000,)，表示有 60000 个标签，每个标签是一个数字，表示图片对应的数字\n",
    "* x_test 的形状是 (10000, 784)，表示有 10000 张图片，每张图片有 784 个像素点\n",
    "* t_test 的形状是 (10000,)，表示有 10000 个标签，每个标签是一个数字，表示图片对应的数字"
   ],
   "id": "bf95e51d31622368"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 取训练图像的第一张看看\n",
    "from PIL import Image # 用于处理图像\n",
    "def img_show(img): # 定义一个函数，用于显示图像，img 是一个一维数组，包含 784 个像素点\n",
    "    pil_img = Image.fromarray(np.uint8(img)) # 将 NumPy 数组转换为 PIL 图像，np.uint8 表示将数据转换为 8 位无符号整数，即 0-255 之间的整数\n",
    "    pil_img.show() # 显示图像\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=False) # 读入 MNIST 数据集\n",
    "img = x_train[0] # 取训练图像的第一张\n",
    "label = t_train[0] # 取训练标签的第一张\n",
    "print(label) # 打印标签\n",
    "img = img.reshape(28, 28) # 将一维数组转换为二维数组\n",
    "img_show(img) # 显示图像"
   ],
   "id": "dff592f66c8f9df9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "接下来实现推理处理\n",
    "```\n",
    "输入的图片是 28x28 的灰度图像，所以输入层有 784 个节点\n",
    "最终的输出是 0-9 的数字，所以输出层有 10 个节点\n",
    "定义两个隐藏层\n",
    "第一个隐藏层有 50 个节点，用于提取图像的特征\n",
    "第二个隐藏层有 100 个节点，用于进一步提取图像的特征\n",
    "```"
   ],
   "id": "52ab1ed88c1c7e56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T14:57:29.954822Z",
     "start_time": "2025-10-16T14:57:29.605953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get_data 函数用于获取 MNIST 数据集的测试数据\n",
    "def get_data():\n",
    "    (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True, normalize=True, one_hot_label=False)\n",
    "    return x_test, t_test\n",
    "\n",
    "# init_network 函数用于初始化神经网络的权重和偏置\n",
    "def init_network():\n",
    "    with open(\"/Users/Crimson/PycharmProjects/DeepLearning/pickle/sample_weight.pkl\", 'rb') as f:\n",
    "        network = pickle.load(f)\n",
    "    return network\n",
    "\n",
    "# 定义激活函数 sigmoid 和 恒等函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def identity_function(x):\n",
    "    return x\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "\n",
    "# predict 函数用于进行前向传播，计算神经网络的输出\n",
    "def predict(network, x):\n",
    "    W1, W2, W3 = network['W1'], network['W2'], network['W3']\n",
    "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
    "\n",
    "    a1 = np.dot(x, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    z2 = sigmoid(a2)\n",
    "    a3 = np.dot(z2, W3) + b3\n",
    "    y = softmax(a3)\n",
    "    return y\n",
    "\n",
    "x, t = get_data() # 获取测试数据\n",
    "network = init_network() # 初始化神经网络\n",
    "accuracy_cnt = 0 # 预测正确的数量\n",
    "for i in range(len(x)): # 遍历所有测试数据\n",
    "    y = predict(network, x[i]) # 进行前向传播，计算神经网络的输出\n",
    "    p = np.argmax(y) # 取输出中最大的值的索引, max 和 argmax 的区别是 max 取最大值，argmax 取最大值的索引，这里取索引是因为索引对应的数字就是预测的结果\n",
    "     # np.argmax(a) 返回数组 a 中最大值的索引\n",
    "     # np.max(a) 返回数组 a 中的最大值\n",
    "     # 例如，a = [0.1, 0.5, 0.2]，则 np.argmax(a) 返回 1，np.max(a) 返回 0.5\n",
    "     # 因为索引 1 对应的值是 0.5，是数组中的最大值\n",
    "     # 这里的 p 就是神经网络预测的数字\n",
    "     # t[i] 是真实的标签\n",
    "    if p == t[i]: # 如果预测值等于真实值，预测正确\n",
    "        accuracy_cnt += 1 # 预测正确的数量加 1\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) # 打印预测正确的比例"
   ],
   "id": "7a00f7322d9f85ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9352\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T15:04:38.423184Z",
     "start_time": "2025-10-16T15:04:38.327522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 批处理\n",
    "# 相当与输入层的一位数组变成二维数组，当用二维数组取前向传播时，一次可以处理多个数据\n",
    "x, t = get_data() # 获取测试数据\n",
    "network = init_network() # 初始化神经网络\n",
    "batch_size = 100 # 批处理的数量\n",
    "accuracy_cnt = 0 # 预测正确的数量\n",
    "for i in range(0, len(x), batch_size): # 每次取 batch_size 个数据进行处理\n",
    "    x_batch = x[i:i+batch_size] # 取出批处理的数据\n",
    "    y_batch = predict(network, x_batch) # 进行前向传播\n",
    "    p = np.argmax(y_batch, axis=1) # 取输出中最大的值的索引, axis=1 取每一行的最大值的索引，返回一个一维数组\n",
    "    accuracy_cnt += np.sum(p == t[i:i+batch_size]) # 计算预测正确的数量 # p == t[i:i+batch_size] 返回一个布尔数组，表示每个预测值是否等于真实值，np.sum() 对布尔数组求和，True 计为 1，False 计为 0\n",
    "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x))) #"
   ],
   "id": "c79f2cea44e734c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9207\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
